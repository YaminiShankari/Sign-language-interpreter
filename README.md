# Sign-language-interpreter
In this project, my model is trained to identify 4 distinct signs based on American Sign Language (ASL) namely hello, thank you, yes and no. 

How It Works?
1) Opens your webcam
2) Detects your hand using computer vision techniques
3) Extracts image features 
4) Feeds them into a trained ML model
5) Displays the corresponding word on screen

Future Enhancements:
1) Sentence formation and word prediction
2) Support for regional sign languages (ISL, BSL, etc.)
3) Voice synthesis for interpreted text
4) Mobile app version (using Kivy or Flutter + TensorFlow Lite)
